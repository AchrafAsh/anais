{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from data import get_train_test_split\n",
    "from models.utils import damerau_levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = get_train_test_split(\"10_ports.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters = string.printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.char_to_int = {}\n",
    "        self.int_to_char = {}\n",
    "        self.build_vocab()\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        all_characters = string.printable\n",
    "        self.char_to_int[\"\"] = 0\n",
    "        self.int_to_char[0] = \"\"\n",
    "        idx = 1\n",
    "        for c in all_characters:\n",
    "            self.char_to_int[c] = idx\n",
    "            self.int_to_char[idx] = c\n",
    "            idx += 1\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.int_to_char[idx]\n",
    "    \n",
    "    def encode(self, text):\n",
    "        return [self.char_to_int[c] for c in text]\n",
    "    \n",
    "    def decode(self, x):\n",
    "        return \"\".join([\n",
    "            self.int_to_char[i] for i in x\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans:\n",
    "    def __init__(self, k, centroids, vocab):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            k (int): number of centroids\n",
    "            centroids (list<str>): list of initial centroids (text)\n",
    "            vocab (Vocabulary):\n",
    "        \"\"\"\n",
    "        assert k == len(centroids)\n",
    "        self.k = k\n",
    "        self.centroids = centroids\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def distance(self, s1, s2):\n",
    "        \"\"\"Compute Damereau distance\n",
    "        \"\"\"\n",
    "        if type(s1) != str: s1 = self.vocab.decode(s1)\n",
    "        if type(s2) != str: s2 = self.vocab.decode(s2)\n",
    "        \n",
    "        return damerau_levenshtein_distance(s1,s2)\n",
    "            \n",
    "    \n",
    "    def __call__(self, text):\n",
    "        \"\"\"Finds the closes centroid\n",
    "        \n",
    "        Parameters:\n",
    "            text (str):\n",
    "        \n",
    "        Returns:\n",
    "            str: closes centroid\n",
    "        \"\"\"\n",
    "        closest_centroid = self.centroids[0]\n",
    "        closest_dist = self.distance(text, closest_centroid)\n",
    "        \n",
    "        for i in range(1, self.k):\n",
    "            if self.distance(text, self.centroids[i]) < closest_dist:\n",
    "                closest_dist = self.distance(text, self.centroids[i])\n",
    "                closest_centroid = self.centroids[i]\n",
    "        \n",
    "        return closest_centroid\n",
    "    \n",
    "    def init_clusters(self):\n",
    "        clusters = {}\n",
    "        for i in range(self.k): \n",
    "            clusters[i] = [self.centroids[i]]\n",
    "        return clusters\n",
    "    \n",
    "    def fit(self, dataset, iterations):\n",
    "        n = len(dataset)\n",
    "        max_length = max([\n",
    "            len(text) for text in dataset[\"destination\"].tolist()\n",
    "        ])\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            clusters = self.init_clusters()\n",
    "            \n",
    "            # create new clusters\n",
    "            for i in range(n):\n",
    "                x = dataset[\"destination\"][i]\n",
    "                \n",
    "                centroid = self(x)\n",
    "                for j in range(self.k):\n",
    "                    if centroid == clusters[j][0]: clusters[j].append(x)\n",
    "            \n",
    "            # compute new centroids\n",
    "            for j in range(self.k):\n",
    "                cluster = clusters[j]\n",
    "                centroid = []\n",
    "                for i in range(len(cluster)):\n",
    "                    idx = 0\n",
    "                    while True:\n",
    "                        if idx > max([len(text) for text in cluster]): break\n",
    "                        \n",
    "                        \n",
    "                        centroid[idx] = np.sum([self.vocab.encode(text[idx]) \n",
    "                                                if idx < len(text) else 0 \n",
    "                                                for text in cluster], axis=1)\n",
    "                        \n",
    "                        for i in range(len(centroid)):\n",
    "                            idx = np.argmax(centroid[i])\n",
    "                            centroid[i] = np.zeros(len(self.vocab))\n",
    "                            centroid[i][idx] = 1\n",
    "                            centroid = self.vocab.encode(centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()\n",
    "model = Kmeans(k=10, centroids=train.loc[np.random.randint(1,len(train), 10)][\"code\"].tolist(), \n",
    "               vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-2581babc711c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-7b79ba09c563>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, iterations)\u001b[0m\n\u001b[1;32m     70\u001b[0m                         centroid[idx] = np.sum([self.vocab.encode(text[idx]) \n\u001b[1;32m     71\u001b[0m                                                 \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                                                 for text in cluster], axis=1)\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "model.fit(train, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
